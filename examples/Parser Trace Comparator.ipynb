{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:02:39.750683Z",
     "start_time": "2022-04-21T19:02:36.460593Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import site\n",
    "from sparclur.parsers import Arlington, MuPDF, PDFCPU, Poppler, QPDF, XPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:02:40.727069Z",
     "start_time": "2022-04-21T19:02:40.719826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MuPDF in module sparclur.parsers._mupdf:\n",
      "\n",
      "class MuPDF(sparclur._tracer.Tracer, sparclur._hybrid.Hybrid, sparclur._reforge.Reforger)\n",
      " |  MuPDF(doc: Union[str, bytes], skip_check: Union[bool, NoneType] = None, hash_exclude: Union[str, List[str], NoneType] = None, page_hashes: Union[int, Tuple[Any], NoneType] = None, validate_hash: bool = False, parse_streams: Union[bool, NoneType] = None, binary_path: Union[str, NoneType] = None, temp_folders_dir: Union[str, NoneType] = None, dpi: Union[int, NoneType] = None, cache_renders: Union[bool, NoneType] = None, timeout: Union[int, NoneType] = None, ocr: Union[bool, NoneType] = None)\n",
      " |  \n",
      " |  MuPDF parser\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MuPDF\n",
      " |      sparclur._tracer.Tracer\n",
      " |      sparclur._hybrid.Hybrid\n",
      " |      sparclur._text_extractor.TextExtractor\n",
      " |      sparclur._renderer.Renderer\n",
      " |      sparclur._text_compare.TextCompare\n",
      " |      sparclur._reforge.Reforger\n",
      " |      sparclur._parser.Parser\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, doc: Union[str, bytes], skip_check: Union[bool, NoneType] = None, hash_exclude: Union[str, List[str], NoneType] = None, page_hashes: Union[int, Tuple[Any], NoneType] = None, validate_hash: bool = False, parse_streams: Union[bool, NoneType] = None, binary_path: Union[str, NoneType] = None, temp_folders_dir: Union[str, NoneType] = None, dpi: Union[int, NoneType] = None, cache_renders: Union[bool, NoneType] = None, timeout: Union[int, NoneType] = None, ocr: Union[bool, NoneType] = None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      doc : str or bytes\n",
      " |          Either the path to the PDF or the raw bytes of the PDF\n",
      " |      skip_check : bool\n",
      " |          Flag for skipping the parser check.\n",
      " |      hash_exclude : str or List[str]\n",
      " |          Specifies any subclass SPARCLUR hashes that should be excluded from this parser instantiation. Can be one or\n",
      " |          more of the following: 'Renderer', 'Tracer', 'Text Extractor', 'Metadata Extractor', and/or 'Font Extractor'\n",
      " |      page_hashes:\n",
      " |      The description is missing.\n",
      " |      validate_hash:\n",
      " |      The description is missing.\n",
      " |      parse_streams : bool\n",
      " |          Indicates whether mutool clean should be called with -s or not. -s parses into the content streams of the\n",
      " |          PDF.\n",
      " |      binary_path : str\n",
      " |          If the mutool binary is not in the system PATH, add the path to the binary here. Can also be used to trace\n",
      " |          specific versions of the binary.\n",
      " |      temp_folders_dir : str\n",
      " |          Path to create the temporary directories used for temporary files.\n",
      " |      dpi:\n",
      " |      The description is missing.\n",
      " |      cache_renders:\n",
      " |      The description is missing.\n",
      " |      timeout : int\n",
      " |          Specify a timeout for parsing commands\n",
      " |      ocr:\n",
      " |      The description is missing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_name()\n",
      " |      Return the SPARCLUR defined name for the parser.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Parser name\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  streams_parsed\n",
      " |  \n",
      " |  validate_renderer\n",
      " |      Performs a validity check for this tracer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[str, Any]\n",
      " |  \n",
      " |  validate_text\n",
      " |      Performs a validity check for this text extractor.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[str, Any]\n",
      " |  \n",
      " |  validate_tracer\n",
      " |      Performs a validity check for this tracer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sparclur._tracer.Tracer:\n",
      " |  \n",
      " |  can_trace\n",
      " |  \n",
      " |  cleaned\n",
      " |      Return a normalized collection of the warnings and errors with occurrence counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[str, int]\n",
      " |          A dictionary with each normalized message as the key and the occurrence count as the value\n",
      " |  \n",
      " |  messages\n",
      " |      Return the error and warnings for the document passed into the Parser instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      List[str]\n",
      " |          The list of all raw messages from the parser over the given document\n",
      " |  \n",
      " |  sparclur_hash\n",
      " |      The SPARCLUR hash attempts to distill the information from the different parser tools: image hashes for the\n",
      " |      renders and sets of shingled murmur hashes for the text extraction, metadata, trace messages, and fonts. These\n",
      " |      are collected and then can be used to compare two documents and a distance measure is calculated. This is most\n",
      " |      relevant in 2 specific cases: the first is trying to find evidence of non-determinism in a parser and the\n",
      " |      second is to quickly compare differences between parser translations of a document (See the Reforge class of\n",
      " |      tools).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SparclurHash\n",
      " |          The class that holds the SPARCLUR hashes for each tool and provides an API for comparing two hashes.\n",
      " |  \n",
      " |  validity\n",
      " |      Returns the validity statuses from each of the relevant tools of the parser and an overall validity for the\n",
      " |      document. If any of the tools have a warning or error the overall will show that otherwise all of the tools need\n",
      " |      to mark the document as valid for the overall status to be valid.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[str, Dict[str, Any]]\n",
      " |          A dictionary of dictionaries laying out the validity and statuses for the parser tools.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sparclur._hybrid.Hybrid:\n",
      " |  \n",
      " |  compare_ocr(self, page=None, shingle_size=4)\n",
      " |      Method that compares the OCR result to the built-in text extraction.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      page : int\n",
      " |          Indicates which page the comparison should be run over. If 'None', all pages are compared.\n",
      " |      shingle_size : int, default=4\n",
      " |          The size of the token shingles used in the Jaccard similarity comparison between the OCR and the text\n",
      " |          extraction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The Jaccard similarity between the OCR and the text extraction (for the specified shingle size).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sparclur._hybrid.Hybrid:\n",
      " |  \n",
      " |  ocr\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sparclur._renderer.Renderer:\n",
      " |  \n",
      " |  clear_renders(self)\n",
      " |      Clears any PIL's that have been retained in the renderer object.\n",
      " |  \n",
      " |  compare(self, other: 'Renderer', page=None, full=False)\n",
      " |      Performs a structural similarity comparison between two renders\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Renderer\n",
      " |          The other Parser and document to compare this Parser and document to.\n",
      " |      page : int, List[int], default=None\n",
      " |          Specifiy whether a single page or specific collection of pages should be compared.\n",
      " |          If 'None', all pages are compared.\n",
      " |      full : bool, default=False\n",
      " |          Return an image of the comparison of the two document renders for each page or the specified page.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[int, PRCSim] or PRCSim\n",
      " |  \n",
      " |  get_renders(self, page: Union[int, List[int]] = None)\n",
      " |      Return the renders of the object document. If page is None, return the entire rendered document. Otherwise\n",
      " |      returns the specified page only.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      page: int, List[int], or None\n",
      " |          zero-indexed page or list of pages to be rendered. Returns the whole document if None\n",
      " |      Returns\n",
      " |      -------\n",
      " |      PngImageFile or Dict[int, PngImageFile]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sparclur._renderer.Renderer:\n",
      " |  \n",
      " |  can_render\n",
      " |  \n",
      " |  logs\n",
      " |      View any gathered logs.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict[int, Dict[str, Any]]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sparclur._renderer.Renderer:\n",
      " |  \n",
      " |  caching\n",
      " |      Returns the caching setting for the renderer.\n",
      " |      \n",
      " |      If caching is set to true, the collection of all rendered PIL's is retained in the object. Otherwise,\n",
      " |      the renders will be regenerated every time the get_renders method is called.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  dpi\n",
      " |      Return dots per inch\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sparclur._text_compare.TextCompare:\n",
      " |  \n",
      " |  clear_text(self)\n",
      " |      Clear any text that has already been extracted for the document\n",
      " |  \n",
      " |  compare_text(self, other: 'TextCompare', page=None, shingle_size=4)\n",
      " |      Shingles the parsed tokens into the specified n-grams and then compares the two token sets and calculates the\n",
      " |      Jaccard similarity.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : TextCompare\n",
      " |          The Text Extraction, Renderer, or Hybrid parser to comapre to this parser\n",
      " |      page : int\n",
      " |          The 0-indexed page to compare. If `None`, Use the tokens from the entire document\n",
      " |      shingle_size : int, default=4\n",
      " |          The size of the shingled n-grams\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The Jaccard Similarity score\n",
      " |  \n",
      " |  get_text(self, page: int = None)\n",
      " |      Return the extracted text from the document. If page is None, return all text from the document. Otherwise\n",
      " |      returns the text for the specified text only.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      page: int or None\n",
      " |          zero-indexed page to extract text from. Returns the whole document if None\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or Dict[int, str]\n",
      " |  \n",
      " |  get_tokens(self, page: int = None)\n",
      " |      Return the parsed text tokens from the document. If page is None, return all token sets from the document.\n",
      " |      Otherwise returns the text for the specified text only.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      page: int or None\n",
      " |          zero-indexed page to extract text from. Returns the whole document if None\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or Dict[int, str]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sparclur._text_compare.TextCompare:\n",
      " |  \n",
      " |  can_extract_text\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sparclur._reforge.Reforger:\n",
      " |  \n",
      " |  save_reforge(self, save_path: str)\n",
      " |      Saves the reforged document to the specified file location.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      save_path : str\n",
      " |          The file name and location to save the document.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sparclur._reforge.Reforger:\n",
      " |  \n",
      " |  can_reforge\n",
      " |  \n",
      " |  reforge\n",
      " |      The resulting reforged document.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes\n",
      " |  \n",
      " |  reforge_result\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sparclur._parser.Parser:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sparclur._parser.Parser:\n",
      " |  \n",
      " |  doc\n",
      " |      Return the path to the document that is being run through the parser instance or the first 15 bytes if a binary\n",
      " |      was passed to the parser.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or bytes\n",
      " |          String of the document path or first 15 bytes of the binary\n",
      " |  \n",
      " |  num_pages\n",
      " |      Determine the number of pages in the PDF according to the parser. If the parser does not support page number\n",
      " |      extraction (e.g. Arlington DOM Checker) this returns None. If the parser fails to load and determine the\n",
      " |      number of pages, 0 is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of pages in the document\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sparclur._parser.Parser:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  temp_folders_dir\n",
      " |  \n",
      " |  timeout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MuPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:06.457072Z",
     "start_time": "2022-04-21T19:05:06.454195Z"
    }
   },
   "outputs": [],
   "source": [
    "hello_world = os.path.join(sys.prefix, 'etc', 'sparclur', 'resources', 'hello_world_hand_edit.pdf')\n",
    "#If the above does not load try the below. Otherwise any path to a PDF can be used here.\n",
    "# hello_world = os.path.join(site.USER_BASE, 'etc', 'sparclur', 'resources', 'hello_world_hand_edit.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load up an instance of MuPDF parsing the document. The available API calls are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:07.624507Z",
     "start_time": "2022-04-21T19:05:07.615343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_pages:\t(Property) Returns number of pages in the document\n",
       "can_reforge:\t(Property) Boolean for whether or not reforge capability is present\n",
       "reforge:\t(Property) Returns the raw binary of the reconstructed PDF\n",
       "reforge_result:\t(Property) Message conveying the success or failure of the reforging\n",
       "save_reforge:\tSave the reforge to the specified file location\n",
       "can_extract_text:\t(Property) Boolean for whether or not text extraction is present\n",
       "get_text:\tReturn a dictionary of pages and their extracted texts\n",
       "clear_text:\tClear the cache of text extraction\n",
       "get_tokens:\tReturn a dictionary of the parsed text tokens\n",
       "compare_text:\tReturn the Jaccard similarity of the shingled tokens between two text extractors\n",
       "can_render:\tBoolean for whether or not rendering capability is present\n",
       "validate_renderer:\t(Property) Determines the PDF validity for rendering process\n",
       "logs:\t(Property) Any logs collected during the rendering process\n",
       "caching:\t(Property) Whether renders are cached or not\n",
       "clear_renders:\tClears any renders that have been cached inside this object\n",
       "dpi:\t(Property) The DPI setting for this object\n",
       "get_renders:\tRetrieve the render for the specified page or all pages if not specified\n",
       "compare:\tCompare the renders for this object with the renders of another Renderer\n",
       "validate_text:\t(Property) Determines the PDF validity for the text extraction process\n",
       "compare_ocr:\tCompares the OCR of the document with the text extraction\n",
       "can_trace:\t(Property) Boolean for whether or not trace collection capability is present\n",
       "validate_tracer:\t(Property) Determines the PDF validity for the tracing process\n",
       "messages:\t(Property) The list of raw messages from the parser\n",
       "cleaned:\t(Property) A dictionary of normalized messages with their counts"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mupdf = MuPDF(hello_world)\n",
    "mupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the trace messages from parsing this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:12.159078Z",
     "start_time": "2022-04-21T19:05:12.089525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mutool version 1.16.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['error: expected generation number (0 ? obj)',\n",
       " 'warning: trying to repair broken xref',\n",
       " 'warning: repairing PDF document']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mupdf.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:20.430314Z",
     "start_time": "2022-04-21T19:05:20.420790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error: expected generation number': 1,\n",
       " 'warning: trying to repair broken xref': 1,\n",
       " 'warning: repairing PDF document': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mupdf.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:21.991238Z",
     "start_time": "2022-04-21T19:05:21.986766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': False, 'status': 'Rejected', 'info': 'Errors returned'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mupdf.validate_tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do the same for Poppler and QPDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:27.560843Z",
     "start_time": "2022-04-21T19:05:27.554766Z"
    }
   },
   "outputs": [],
   "source": [
    "poppler = Poppler(hello_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:28.006708Z",
     "start_time": "2022-04-21T19:05:28.002512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_pages:\t(Property) Returns number of pages in the document\n",
       "can_reforge:\t(Property) Boolean for whether or not reforge capability is present\n",
       "reforge:\t(Property) Returns the raw binary of the reconstructed PDF\n",
       "reforge_result:\t(Property) Message conveying the success or failure of the reforging\n",
       "save_reforge:\tSave the reforge to the specified file location\n",
       "can_extract_image_data:\t(Property) Boolean for whether or not image data extraction \n",
       "                                                capability is present\n",
       "contains_jpeg:\t(Property) Returns True if jpeg data was extracted from the PDF\n",
       "contains_images:\t(Property) Returns True if image data was extracted from the PDF\n",
       "images:\t(Property) Returns the image data that was extracted from the PDF\n",
       "validate_image_data:\t(Property) Determines the PDF validity for image data extraction\n",
       "can_extract_font:\t(Property) Boolean for whether or not font extraction is present\n",
       "non_embedded_fonts:\t(Property) Returns true if the document is missing non-system fonts\n",
       "fonts:\t(Property) Returns the font information for the PDF\n",
       "validate_fonts:\t(Property) Determines the PDF validity for font info extraction\n",
       "can_extract_text:\t(Property) Boolean for whether or not text extraction is present\n",
       "get_text:\tReturn a dictionary of pages and their extracted texts\n",
       "clear_text:\tClear the cache of text extraction\n",
       "get_tokens:\tReturn a dictionary of the parsed text tokens\n",
       "compare_text:\tReturn the Jaccard similarity of the shingled tokens between two text extractors\n",
       "can_render:\tBoolean for whether or not rendering capability is present\n",
       "validate_renderer:\t(Property) Determines the PDF validity for rendering process\n",
       "logs:\t(Property) Any logs collected during the rendering process\n",
       "caching:\t(Property) Whether renders are cached or not\n",
       "clear_renders:\tClears any renders that have been cached inside this object\n",
       "dpi:\t(Property) The DPI setting for this object\n",
       "get_renders:\tRetrieve the render for the specified page or all pages if not specified\n",
       "compare:\tCompare the renders for this object with the renders of another Renderer\n",
       "validate_text:\t(Property) Determines the PDF validity for the text extraction process\n",
       "compare_ocr:\tCompares the OCR of the document with the text extraction\n",
       "can_trace:\t(Property) Boolean for whether or not trace collection capability is present\n",
       "validate_tracer:\t(Property) Determines the PDF validity for the tracing process\n",
       "messages:\t(Property) The list of raw messages from the parser\n",
       "cleaned:\t(Property) A dictionary of normalized messages with their counts"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:28.719772Z",
     "start_time": "2022-04-21T19:05:28.574643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No warnings']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poppler.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:29.504270Z",
     "start_time": "2022-04-21T19:05:29.496077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': True, 'status': 'Valid'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poppler.validate_tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:30.421728Z",
     "start_time": "2022-04-21T19:05:30.414545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_pages:\t(Property) Returns number of pages in the document\n",
       "can_extract_metadata:\t(Property) Boolean for whether or not metadata extraction capability is present\n",
       "validate_metadata:\t(Property) Determines the PDF validity for metadata extraction\n",
       "metadata:\t(Property) Returns a dictionary of the parsed PDF objects and their key/values\n",
       "metadata_result:\t(Property) Returns a message relating to the success or failure of metadata extraction\n",
       "can_trace:\t(Property) Boolean for whether or not trace collection capability is present\n",
       "validate_tracer:\t(Property) Determines the PDF validity for the tracing process\n",
       "messages:\t(Property) The list of raw messages from the parser\n",
       "cleaned:\t(Property) A dictionary of normalized messages with their counts"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpdf = QPDF(hello_world)\n",
    "qpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:31.098363Z",
     "start_time": "2022-04-21T19:05:31.045607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf: file is damaged',\n",
       " 'WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf (offset 610): xref not found',\n",
       " 'WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf: Attempting to reconstruct cross-reference table',\n",
       " 'WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf (object 4 0, offset 551): expected endstream',\n",
       " 'WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf (object 4 0, offset 488): attempting to recover stream length',\n",
       " 'WARNING: /Users/sdavis/anaconda3/envs/sparclur_test/etc/sparclur/resources/hello_world_hand_edit.pdf (object 4 0, offset 488): recovered stream length: 60',\n",
       " 'qpdf: operation succeeded with warnings']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpdf.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T19:05:32.046085Z",
     "start_time": "2022-04-21T19:05:32.039481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WARNING: file is damaged': 1,\n",
       " 'WARNING: xref not found': 1,\n",
       " 'WARNING: Attempting to reconstruct cross-reference table': 1,\n",
       " 'WARNING: expected endstream': 1,\n",
       " 'WARNING: attempting to recover stream length': 1,\n",
       " 'recovered stream length <x>': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpdf.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sparclur_test]",
   "language": "python",
   "name": "conda-env-sparclur_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
